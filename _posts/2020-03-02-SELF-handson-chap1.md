---
title:  "[핸즈온 머신러닝] 1. 한눈에 보는 머신러닝"
excerpt: "한 줄 요약 : 머신러닝의 개념을 이해하자."
toc: true
toc_sticky: true
header:
  teaser: /assets/images/blog-SELF.jpg
categories:
  - SELF
tags:
  - 핸즈온 머신러닝
  - 머신러닝
  - 
last_modified_at: 2020-03-02
---



# 1장. 한눈에 보는 머신러닝

> 머신러닝의 그림을 조망하고, 주요 영역과 분류, 작업 프로세스를 알아보자.



## 1.1. 머신러닝의 개념

* 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술).
* 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야.  *_아서 사무엘*
* 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다. *_톰 미첼*



## 1.2. 머신러닝의 필요성

머신러닝 기법을 사용하면, 전통적인 프로그래밍 방식에 비해 유지보수가 쉽고, 정확도가 더 높은 모델을 만들 수 있다.

* 기존 솔루션으로는 많은 수동 조정과 규칙이 필요할 때, 머신러닝 모델을 사용하면 코드를 **간단하고 더 잘 수행되도록** 만들 수 있다.

* 전통적인 방식으로는 해결 방법이 없는 복잡한 문제를 해결할 수 있다.

* 새로운 데이터가 계속해서 발생하는 유동적인 환경에 잘 적응할 수 있다.

* 복잡한 문제와 대량의 데이터에서 통찰을 얻을 수 있다.

  > 데이터 마이닝 : 머신러닝 기술을 적용해 대용량의 데이터를 분석함으로써 겉으로 보이지 않던 패턴을 발견하는 것.



## 1.3. 머신러닝 시스템의 종류

### 1.3.1. 사람의 감독 하에 훈련하는지

_"학습하는 동안의 감독 형태나 정보량"_에 따라 다음과 같은 **네 가지 형태**로 분류할 수 있다.



#### 1) 지도학습

* **레이블** 존재 : 알고리즘에 주입하는 훈련 데이터에 답이 포함되어 있음.

* 종류 : **분류**(Classification), **예측**(Prediction)

  * 분류 : 특성을 학습하여 _클래스_를 예측함.

  * 예측 : 특성을 학습하여 타깃이 되는 _수치_를 예측함.

    > **로지스틱 회귀**와 같은 일부 알고리즘의 경우, 분류와 예측 모두에 사용할 수 있음. 

* 지도학습 알고리즘 예

  * k-최근접 이웃
  * 선형 회귀
  * 로지스틱 회귀
  * 서포트 벡터 머신(SVM)
  * 결정트리, 랜덤포레스트
  * 신경망 <sup>일부 신경망은 비지도 학습일 수도, 준지도 학습일 수도 있음.</sup>



#### 2) 비지도 학습

* 레이블 비존재 : 시스템이 정답 없이 학습.

* 비지도 학습 알고리즘 예

  * 군집

    * k-평균
    * 계층 군집 분석(HCA)
    * 기댓값 최대화

  * 시각화, 차원 축소

    > 시각화 : 레이블이 없는 대규모의 고차원 데이터를 도식화 가능한 2D, 3D 표현으로 만듦.
    >
    > 차원 축소 :  정보를 잃지 않으면서 데이터 간소화
    >
    > * 특성 추출 : 상관관계가 있는 여러 특성을 하나로 합침.
    >
    > * 지도학습 알고리즘에서도 지도학습 알고리즘을 사용해 차원을 줄이는 것이 유용할 수 있다.

    * 주성분 분석(PCA)
    * 커널 PCA
    * 지역적 선형 임베딩(LLE)
    * t-SNE

  * 이상치 탐지 : 정상 샘플로 훈련한 시스템에 새로운 샘플이 들어왔을 때 정상인지 이상치인지 판단.

  * 연관 규칙 학습 : 대량의 데이터에서 특성 간 관계 찾음.

    * 어프라이어리
    * 이클렛



#### 3) 준지도 학습

* 레이블 일부 존재.
* 지도 학습 + 비지도 학습의 조합으로 이루어진 알고리즘.



#### 4) 강화 학습

* 학습하는 시스템이 환경을 관찰해서 행동을 실행하고, 그 결과로 보상 혹은 벌점을 받은 뒤 최상의 전략을 학습.
  * 에이전트 : 학습하는 시스템.
  * 정책 : 주어진 상황에서 에이전트가 선택하는 최상의 전략.
  * 학습 : 행동 실행 후, 보상 결과에 따라 행동을 수정하는 과정.
* 사용 예 : 보행 로봇, 알파고.





### 1.3.2. 실시간으로 점진적인 학습을 진행하는지

_"입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지"의 여부_에 따라 다음과 같은 **두 가지 형태**로 분류할 수 있다.



#### 1) 배치(batch) 학습

* 시스템의 **점진적 학습 불가능**. 가용한 데이터를 모두 사용해 훈련.

  * 오프라인 학습 : 시간과 자원을 많이 소모하므로, 오프라인에서 시스템 훈련.
  * 훈련 후, 제품 시스템에 적용해, 더 이상의 학습 없이 실행.

* 문제점

  * 새로운 데이터에 대한 학습이 어려움.

    >  새로운 데이터가 들어올 때, 데이터를 업데이트하고 + 전체 데이터를 사용해 시스템의 새로운 버전을 처음부터 다시 훈련해야 함.

  * 많은 컴퓨팅 자원이 필요함.

  * 자원이 제한된 시스템(스마트폰, 탐사 로봇 등)에서는 적용하기 어려움.



#### 2) 온라인 학습

> 이름은 "온라인 학습"이지만, 전체적인 프로세스는 실시간 시스템이 아닌 오프라인으로 수행되기 때문에, "점진적 학습"이라고 기억해 두자.

* 시스템의 점진적 학습 가능 : 데이터를 순차적으로 한 개씩, 혹은 미니배치 단위로 주입하여 훈련.
* 학습률 : **변화하는 데이터에 얼마나 빠르게 적응할 것인지**를 나타내는 온라인 학습 시스템의 파라미터.
  * **↑** :  빠른 적응 + 이전 데이터 잊어버림.
  * **↓** : 느린 학습 + 새로운 데이터의 잡음, 대표성 없는 데이터 포인트에 둔감. 

* 장점
  * 연속적으로 데이터를 받고, 빠른 변화에 스스로 적응.
  * 컴퓨팅 자원이 제한된 경우 좋음 : 학습 종료 시 이전 데이터 버림.
  * 큰 데이터셋의 경우에도 일부만 읽어들임으로써 학습 가능.
* 단점 : 시스템에 나쁜 데이터가 주입되면 성능이 점진적으로 감소.
  * 시스템 모니터링 + 성능 감소가 감지되면 학습 중지.
  * 이상치 탐지 알고리즘 등을 활용해 비정상 데이터 잡아냄.



### 1.3.3. 어떻게 일반화되는지

머신러닝 시스템은 주어진 훈련 데이터로 학습한 뒤, 본 적 없는 새로운 데이터에도 일반화되어 적용될 수 있어야 한다. 이 때, _"일반화를 위한 접근법"_에 따라 다음과 같은 **두 가지 형태**로 분류할 수 있다.





#### 1) 사례 기반 학습

* 사례를 기억함으로써 학습.
* 유사도 측정을 사용해 새로운 데이터에 일반화.



#### 2) 모델 기반 학습

* 훈련 데이터의 샘플들을 학습한 뒤, 그 샘플들의 모델을 만들어 예측에 사용.
* 학습 프로세스([사이킷런을 이용한 선형 모델의 훈련과 실행](https://github.com/sirzzang/handson-ml/blob/master/01_the_machine_learning_landscape.ipynb))
  * 데이터 분석.
  * 모델 선택.
  * 모델 훈련 : 훈련 데이터를 이용해 학습하며, 효용함수를 극대화하거나, 비용함수를 최소화하는 모델 파라미터 선택.
  * 추론 : 새로운 데이터에 모델을 적용해 예측.



## 1.4. 머신러닝 과정에서의 어려움



### 1.4.1. 나쁜 데이터



#### 1) 충분하지 않은 양의 훈련 데이터

> 데이터의 추가 수집과 알고리즘 개발 사이에서의 트레이드 오프.

* 대부분의 머신러닝 알고리즘은 잘 작동하기 위해 충분히 많은 양의 데이터를 필요로 한다.
* 특히, [복잡한 자연어 중의성 해소](https://www.aclweb.org/anthology/P01-1005/) 논문의 저자들이 밝히듯, 데이터가 충분히 많아지면 여러 머신러닝 알고리즘은 비슷한 성과를 낸다.



#### 2) 대표성 없는 훈련 데이터

* 훈련 데이터가 일반화하기를 원하는 새로운 사례를 잘 대표하지 못한다면, 일반화가 되지 않는다.
* 고려해야 할 주요 문제점
  * 1)의 문제로 인해 샘플을 늘린다. 이 때, 새로운 샘플이 이전의 샘플이나, 혹은 다른 새로운 데이터들을 대표하지 못한다면?
  * 샘플이 작아도, 커도 대표성 문제가 생길 수 있다. 샘플이 너무 작으면 **샘플링 잡음**(우연에 의한 데이터 편향)이, 샘플이 너무 크면 표본 추출 방법에 따라 **샘플링 편향**이 생길 수 있다.



#### 3) 낮은 품질의 데이터

* 훈련 데이터에 결측치, 이상치, 에러, 잡음 등이 있는 경우, 머신러닝 시스템은 내재된 패턴을 찾는 데에 어려움을 겪는다.
* 훈련 데이터 정제를 통해 문제를 해결한다.
  * 명확한 이상치 : 무시하거나, 수동으로 잘못된 것을 고친다.
  * 결측치 : 특성을 무시하거나, 샘플을 무시하거나, 빠진 값을 채우거나, 특성을 넣은 모델과 제외한 모델을 따로 훈련시킨다.



#### 4) 관련 없는 특성(_Garbage In, Garbage Out_)

* 훈련 데이터에 관련 있는 특성이 많을수록 머신러닝 시스템이 잘 학습한다.
* 특성 공학(Feature Engineering) : 훈련에 사용할 좋은 특성을 찾는 것.
  * 특성 선택 : 가지고 있는 특성 중 훈련에 가장 유용한 특성 선택.
  * 특성 추출 : 특성을 결합해 더 유용한 특성을 만듦.
  * 새로운 데이터를 수집해 새로운 특성을 만듦.



### 1.4.2. 나쁜 알고리즘



#### 1) 훈련 데이터 과대적합(Overfitting)

* 모델이 훈련 데이터에는 잘 맞지만, 일반성이 떨어져 새로운 데이터에 잘 맞지 않는 경우.
* 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생.
* 해결 방법
  * 파라미터 수가 적은 모델 선택.
  * 훈련 데이터의 특성 수 감소.
  * 규제 : 모델에 제약을 가해 단순화.
  * 훈련 데이터 추가 수집.
  * 훈련 데이터의 잡음 감소 : 오류 데이터 수정, 이상치 제거 등.
* 고려 사항 : *데이터에 완벽히 맞추는 것*과 *일반화를 위해 단순한 모델을 만드는 것* 사이의 **균형**.



#### 2) 훈련 데이터 과소적합(Underfitting)

* 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 경우.
* 해결 방법
  * 파라미터 수가 많은 모델 선택.
  * 학습 알고리즘에 더 좋은 특성 제공.
  * 모델의 제약 감소.



## 1.5. 테스트와 검증

* 모델이 새로운 샘플에 얼마나 잘 일반화되는지를 평가하기 위해 검증을 진행함.
  * 훈련 데이터 분할 : 훈련 세트, 테스트 세트.
    * 훈련 세트를 사용해 모델 훈련.
    * 테스트 세트를 사용해 모델 테스트.
  * 일반화 오차 : 새로운 샘플에 대한 오류 비율.
* 검증 세트 : 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만드는 것을 방지.
  * 훈련 데이터 분할 : 훈련 세트, 테스트 세트, 검증 세트.
    * 훈련 세트 : 다양한 하이퍼파라미터로 여러 모델 훈련.
    * 검증 세트 : 최상의 성능을 내는 모델 및 하이퍼파라미터 선택.
    * 테스트 세트 : 단 한 번의 최종 테스트.
  * 교차 검증 : 훈련 데이터에서 검증 세트로 너무 많은 양을 사용하지 않기 위해, 훈련 세트를 여러 subset으로 나누고, 각 모델을 subset의 조합으로 훈련시킨 뒤 나머지 부분으로 검증.



---



# 실습

## 삶의 만족도와 1인당 GDP의 관계

* 새로운 OECD 데이터 활용하여 진행.







---

# 배운 점



# 더 공부하고 싶은 것

* prepare_country_stats 함수에 대한 code inspection