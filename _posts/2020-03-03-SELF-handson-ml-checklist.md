---
title:  "[핸즈온 머신러닝] 머신러닝 프로젝트 체크리스트"
excerpt: "한 줄 요약 : 프로젝트 진행 시 항상 과정을 체크하자."
toc: true
toc_sticky: true
header:
  teaser: /assets/images/blog-SELF.jpg
categories:
  - SELF
tags:
  - 핸즈온 머신러닝
  - 머신러닝
  - 체크리스트
last_modified_at: 2020-03-03
---



# 머신러닝 프로젝트 체크리스트



## 주요 단계

머신러닝의 주요 8단계는 다음과 같다.

1. 문제를 정의하고 큰 그림을 그린다.
2. 데이터를 수집한다.
3. 통찰을 얻기 위해 데이터를 탐색한다.
4. 데이터에 내재된 패턴이 머신러닝 알고리즘에 잘 드러나도록 데이터를 준비한다.
5. 여러 다른 모델을 시험해보고 가장 좋은 몇 개를 고른다.
6. 모델을 세밀하게 튜닝하고, 이들을 연결해 최선의 솔루션을 만든다.
7. 솔루션을 출시한다.
8. 시스템을 론칭하고 모니터링, 유지, 보수한다.





## 1단계. 문제 정의

1. 목표를 비즈니스 용어로 정의한다.
2. 이 솔루션은 어떻게 사용될 것인가?
3. (만약 있다면) 현재 솔루션이나 차선책은 무엇인가?
4. 어떤 문제라고 정의할 수 있나(지도/비지도, 온라인/오프라인 등)?
5. 성능을 어떻게 측정해야 하나?
6. 성능 지표가 비즈니스 목표에 연결되어 있나?
7. 비즈니스 목표에 도달하기 위해 필요한 최소한의 성능은 얼마인가?
8. 비슷한 문제가 있나? 이전의 방식이나 도구를 재사용할 수 있나?
9. 해당 분야의 전문가가 있나?
10. 수동으로 문제를 해결하는 방법은 무엇인가?
11. 팀에서 세운 가정을 나열하자.
12. 가정을 검증하자.





## 2단계. 데이터 수집

> 새로운 데이터를 쉽게 얻을 수 있도록, 최대한 **자동화**한다.



1. 필요한 데이터와 양을 나열한다.
2. 데이터를 얻을 수 있는 곳을 찾아 기록한다.
3. 얼마나 많은 공간이 필요한지 확인한다.
4. 법률상 의무가 있는지 확인하고, 필요하다면 인가를 받는다.
5. 접근 권한을 획득한다.
6. 작업 환경을 만든다(충분한 저장공간으로).
7. 데이터를 수집한다.
8. 데이터를 조작하기 편리한 형태로 변환한다(데이터 자체는 바꾸지 않는다).
9. 민감한 정보가 삭제되었거나 보호되었는지 검증한다(*ex. 개인정보 비식별화*)
10. 데이터의 크기와 타입(*ex. 시게열, 표본, 지리정보 등*)을 확인한다.
11. 테스트 세트를 샘플링하여 따로 떼어놓고, **절대 들여다보지 않는다!**





## 3단계. 데이터 탐색

> 해당 분야의 전문가에게 조언을 구한다.



1. 데이터 탐색을 위해 복사본을 생성한다.(필요하다면 샘플링하여 적절한 크기로 줄인다.)
2. 데이터 탐색 결과를 저장하기 위해 Jupyter Notebook을 생성한다.
3. 각 특성의 특징을 조사한다.
   * 이름
   * 타입(범주형, 정수/부동소수, 최댓값/최솟값 유무, 텍스트, 구조적 문자열 등)
   * 누락된 값의 비율(%)
   * 잡음 정도와 잡음의 종류(확률적, 이상치, 반올림 에러 등)
   * 이 작업에 유용할지 여부
   * 분포 형태(가우시안, 균등, 로그 등)
4. (지도 학습 작업이라면) 타깃 속성을 구분한다.
5. 데이터를 시각화한다.
6. 특성 간 상관관계를 조사한다.
7. 수동으로 문제를 해결할 수 있는 방법을 찾는다.
8. 적용 가능한 변환을 찾는다.
9. 추가로 유용한 데이터를 찾는다.(만약 있다면, 2단계로 돌아간다.)
10. 조사한 것을 기록한다.





## 4단계. 데이터 준비

> * 데이터의 복사본으로 작업한다.**원본 데이터셋은 반드시 그대로 보관**
> * 적용한 모든 데이터의 변환은 함수로 만든다.
>   * 다음에 새로운 데이터를 얻을 때 데이터를 쉽게 준비할 수 있다.
>   * 다음 프로젝트에 이 변환을 쉽게 적용할 수 있다.
>   * 테스트 세트를 정제하고 변환하기 위함이다.
>   * 솔루션이 서비스에 투입된 후, 새로운 데이터 샘플을 정제하고 변환하기 위함이다.
>   * 하이퍼파라미터로 준비 단계를 쉽게 선택하기 위함이다.



1. 데이터 정제
   * (선택 사항) 이상치를 수정하거나 삭제한다.
   * 결측치를 채우거나(*ex. 0, 평균, 중간값 등*), 그 행(또는 열)을 제거한다.
2. (선택 사항) 특성 선택 : 작업에 유용하지 않은 정보를 가진 특성을 제거한다.
3. 적절한 특성공학
   * 연속 변수 이산화.
   * 특성 분해((*ex. 범주형, 날짜/시간, 이름/호칭 등*)
   * 가능한 특성 변환 추가(*ex. log(x), sqrt(x), x*^2 등*)
   * 특성을 조합해 가능성 있는 새로운 특성 만들기.
4. 특성 스케일 조정 : 표준화 또는 정규화.





## 5단계. 모델 선택

> * 데이터가 매우 크면, 여러 모델을 일정 시간 안에 훈련시킬 수 있도록 데이터를 샘플링하여 **작은 훈련 세트**로 만든다. 다만, 이렇게 하면 규모가 큰 신경망이나 랜덤 포레스트 등 복잡한 모델은 만들기 어렵다.
> * 가능한 한 최대로 단계를 **자동화**한다.



1. 여러 종류의 모델을 **기본 매개변수**를 사용해 **신속하게, 많이** 훈련시킨다.(*ex. 선형 모델, 나이브 베이지안, SVM, 랜덤 포레스트, 신경망 등*)
2. 성능을 측정하고 비교한다.
   * 각 모델에서 n-겹 교차검증을 사용해 n개 폴드의 성능에 대한 평균과 표준편차를 계산한다.
3. 각 알고리즘에서 가장 두드러진 변수를 분석한다.
4. 모델이 만드는 에러의 종류를 분석한다.
   * 이 에러를 피하기 위해 사람이 사용하는 데이터는 무엇인지 분석한다.
5. 간단한 특성 선택과 특성 공학 단계를 거친다.
6. 이전의 다섯 단계를 한 번이나 두 번 빠르게 반복한다.
7. **다른 종류의 에러**를 만드는 모델을 중심으로, 가장 가능성이 높은 모델을 세 개에서 다섯 개 정도 추린다.





## 6단계. 시스템 정밀 튜닝

> * 이 단계에서는 가능한 한 많은 데이터를 사용하는 것이 좋다. 특히, 세부 튜닝의 마지막 단계로 갈수록 그 중요성이 커진다.
> * 최대한으로 자동화한다.



1. **교차 검증**을 사용해 하이퍼파라미터를 정밀 튜닝한다.
   * 하이퍼파라미터를 사용해 데이터 변환을 선택한다. 특히, 확신이 없는 경우 이 단계가 필요하다.(*ex. 결측치를 0으로 채울 것인지, 중간값으로 채울 것인지, 아예 버릴 것인지?*)
   * 탐색할 하이퍼파라미터의 값이 매우 적지 않다면, `GridSearch`보다 `RandomSearch`를 사용한다. 훈련 시간이 오래 걸린다면, `베이지안 최적화 방법`을 사용한다.(*ex. 가우시안 프로세스 사전확률<sup>Gaussian Process Prior</sup>을 사용한다.)
2. **앙상블 방법**을 시도한다. 좋은 모델들을 연결했을 때, 종종 개별 모델을 실행하는 것보다 더 성능이 높아진다.
3. 최종 모델에 확신이 선 후, 일반화 오차를 추정하기 위해 테스트 세트에서 성능을 측정한다.

> 일반화 오차를 측정했다면, **절대** 모델을 변경해서는 안 된다. 만약 그렇게 하면, 테스트 세트에 과대적합되기 시작한다.





## 7단계. 솔루션 출시

1. 지금까지의 작업을 문서화한다.
2. 발표 자료를 만든다. 먼저 **큰 그림을 부각**시키는 것이 중요하다.
3. 이 솔루션이 어떻게 비즈니스 목표를 달성하는지 설명한다.
4. 작업 과정에서 알게 된 흥미로운 점들을 잊지 않고 설명한다.
   * 성공한 것과 그렇지 못한 것을 설명한다.
   * 팀이 세운 가정과 시스템의 제약을 나열한다.
5. 그래프나 기억하기 쉬운 문장으로 핵심 내용을 전달한다.(*ex. "중간 소득이 주택 가격에 대한 가장 중요한 예측 변수입니다."*)





## 8단계. 시스템 런칭

1. 서비스에 투입하기 위해 솔루션을 준비한다(실제 입력 데이터 연결, 단위 테스트 작성 등).
2. 시스템의 서비스 성능을 일정한 간격으로 확인하고, 성능이 감소됐을 때 알림을 받기 위한 모니터링 코드를 작성한다.
   * 아주 느리게 감소되는 현상에 주의한다. 데이터가 변화함에 따라 모델은 점차 구식(`OutOfDated`)이 되어 간다.
   * 성능 측정에 있어 사람의 개입이 필요할 수도 있다.(*ex. 크라우드소싱 서비스를 통해*)
   * 입력 데이터의 품질도 모니터링한다(*ex. 오작동 센서가 무작위한 값을 보내는 경우, 다른 팀의 출력 품질이 나쁜 경우 등*). 온라인 학습 시스템의 경우 특히 중요하다.
3. 정기적으로 새로운 데이터를 활용해 모델을 다시 훈련시킨다. 가능한 한 **자동화**한다.