---
title:  "[핸즈온 머신러닝] 2. 머신러닝 프로젝트 처음부터 끝까지"
excerpt: "한 줄 요약 : 머신러닝 프로젝트의 전 과정을 이해하자."
toc: true
toc_sticky: true
header:
  teaser: /assets/images/blog-SELF.jpg
categories:
  - SELF
tags:
  - 핸즈온 머신러닝
  - 머신러닝
  - 프로세스
  - 체크리스트
last_modified_at: 2020-03-03
---



# 2장. 머신러닝 프로젝트 처음부터 끝까지

> 1장에서 살펴봤듯, 머신러닝은 데이터 준비 단계, 모니터링 도구 구축, 사람의 평가 파이프라인 세팅, 주기적인 모델 학습 자동화의 단계로 이루어진다. 프로젝트를 진행하기 위해서는 **전체 프로세스**에 익숙해지는 것이 무엇보다 중요하다. 
>
> 예시로 제공되는 캘리포니아 주택 가격 예측 프로젝트를 따라가며, 전체 프로젝트의 과정을 알아보자.



## *머신러닝 체크리스트*

[머신러닝 체크리스트]({{site.url}}/self/SELF-handson-ml-checklist/)를 준비하고, 프로젝트에 따라 수정하며 전체적인 프로세스를 구축하자.





## 2.1. 큰 그림 그리기

### 1) 문제 정의

> 캘리포니아 인구조사 데이터를 활용해 캘리포니아의 주택 가격 예측 모델을 만든다.

* 비즈니스의 목적 : 중간 주택 가격을 예측하여 투자 가치를 결정하는 시스템에 투입한다.

* (만약 있다면) 현재 솔루션의 구성 : 전문가 수동 추정. 오류가 많다.
* 문제 정의 : 지도 학습, 예측(회귀), 배치 학습.



### 2) 성능지표 선택

> 이 프로젝트에서는 RMSE를 선택한다.

* 평균 제곱근 오차(RMSE) 
  * 회귀 문제의 전형적 성능 지표.
  * 유클리디안 노름 : 상대적으로 이상치에 민감.
* 평균 절대 오차(MAE)
  * 맨해튼 노름 : 상대적으로 이상치에 둔감.



### 3) 가정 검사

* 모든 가정을 나열하고 검사.
* 다른 시스템을 담당하는 팀과의 소통 중요.





## 2.2. 데이터 가져오기

* 작업 환경 구축.
* 함수로 로드 단계 자동화.



### 데이터의 분포 살피기

데이터를 가져온 뒤, 깊게 들여다 보기 전에 데이터의 구조, 분포만 확인한다. *테스트 세트* 를 떼어 놓기 전까지는 **절대 더 이상 탐색하지 않는다.**



* 데이터 훑어 보기 : `.head()`

* 데이터에 대한 간략한 설명 : `.info()`

  * 전체 행 수, 결측치가 포함된 열 확인.
  * 각 특성의 data type 확인.

* data type에 따라 분포 확인.

  * 문자열/범주형 : `.value_counts()`

  * 수치형 

    * `.describe()`

    * 히스토그램

      > ![correlation matrix]({{ site.url }}/assets/images/correlation_matrix.png)
      >
      > 
      >
      > 이 프로젝트에서는 다음의 사항을 확인할 수 있다.
      >
      > 1. 중간소득의 표시 단위 : 스케일이 무엇인지, 전처리되었는지 여부를 확인한다.
      >
      > 2. 중간 주택 연도와 중간 주택 가격의 최댓값, 최솟값 한정.
      >
      >    클라이언트 팀과 상의한 뒤,
      >
      >    * 한계 밖 구역에 대한 정확한 레이블을 구하거나,
      >    * 훈련 세트에서 이러한 구역을 제거한다.
      >
      > 3. 특성 간 측정 수치가 달라, 스케일링이 필요하다.
      >
      > 4. 분포를 종 모양으로 변환할 필요가 있다.





## 2.3. 테스트 세트 만들기

* 데이터 스누핑 편향을 방지하기 위해, 훈련 데이터의 일부를 테스트 세트로 떼어 놓는다.

  *"데이터 스누핑 편향이란? 테스트 세트를 미리 들여다봄으로 인해, **테스트 세트에서 겉으로 드러난 패턴에 속아 특정 머신러닝 모델을 선택**하는 것. 시스템 런칭 후 일반화되지 않을 수 있다."*

* 테스트 세트 생성 방법

  * 무작위 샘플링 : 사이킷런 `train_test_split`
  * 계층적 샘플링 : 사이킷런 `StratifiedShuffleSplit`
  * 기타(링크!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!)
    * test_ratio 지정, 수작업.
    * 해시값, 고유식별자(행 인덱스, 새로운 id 컬럼 생성) 활용 : 데이터 업데이트 시.



### 계층적 샘플링

웬만하면, 계층적 샘플링을 활용한다. 이 때 주의해야 할 사항은 다음과 같다.

* **domain knowledge, 전문가의 조언**을 활용해 타깃 속성을 예측하는 데에 중요한 특성을 선택한다.

* 해당 특성을 계층별로 나누어, 새로운 특성을 생성한다.

  > 실습 파일에서 중간 소득 카테고리를 형성한 결과
  >
  > ![income_cat]({{ site.url }}/assets/images/income_category_hist.png)

  * 너무 많은 계층으로 나누면 안 된다.
  * 각 계층 내 샘플의 수가 충분히 커야 한다.

* 테스트 세트를 만든 뒤, 계층 특성을 삭제하고 데이터를 원래 상태로 복원한다.





## 2.4. 데이터 이해를 위한 탐색과 시각화

테스트 세트를 떼어 놓았는지 충분히 확인한다. **훈련 세트에 대해서만 탐색을 진행한다.**

훈련 세트의 크기가 크다면, 탐색을 위한 세트로 훈련 세트를 별도로 샘플링한다. 그렇지 않다면, 전체 훈련 세트로 탐색을 진행한다.

훈련 세트는 절대로 손상되어서는 안 되므로, 반드시 **복사본**을 만들어 진행한다.



### 1) 지리적 데이터 시각화

위도, 경도 등 지리 정보가 있을 때 **산점도**를 그리는 것이 좋다. 산점도를 그리는 기본 코드는 다음과 같다.

```python
>>>data.plot(kind="scatter", x, y)
>>>plt.scatter(data, column)
```



* 데이터 포인트 밀집 구역 파악

위도와 경도에 따라 산점도를 그리면, 데이터 포인트가 밀집된 지역을 파악할 수 있다. 밀집된 구역을 잘 나타내기 위해서, 적절한 크기의 투명도 옵션(`alpha`)을 줄 수 있다. 

> 실습 예제에서는, 주택이 밀집되어 있는 영역을 나타낸다. 투명도 옵션에 따라 밀집된 구역이 어떻게 나타나는지 비교할 수 있다.
>
> | 좋은 시각화                                                  | 나쁜 시각화 예                                               |
> | ------------------------------------------------------------ | ------------------------------------------------------------ |
> | ![alpha]({{ site.url }}/assets/images/better_visualization_plot.png) | ![nonalpha]({{ site.url }}/assets/images/bad_visualization_plot.png) |



* 다른 데이터와 연결해 시각화

원의 반지름을 나타내는 `s`, 원의 색을 나타내는 `c` 옵션 등을 활용해 다른 데이터와 한 번에 시각화할 수 있다.

> 실습 예제에서는, 원의 반지름으로 구역의 인구를, 원의 색깔로 가격을 나타내어 시각화했다.
>
> ![scatter_additional]({{ site.url }}/assets/images/housing_prices_scatterplot.png)





이렇게 시각화한 자료를 지리 정보를 나타내는 지도 등과 함께 본다면, 더 좋은 통찰을 얻을 수 있다.

> ㅇㅇ
>
> 실습 예제에서의 시각화를 통해 다음과 같은 점을 알 수 있다.
>
> 1. Bay Area, LA, San Diego 등의 지역에 주택이 밀집되어 있다.
> 2. 주택 가격은 지역(*ex. 바다와 밀접한 곳*), 인구 밀도와 연관이 크다. 
> 3. 이후 군집 알고리즘을 사용해 주요 군집을 찾고, 군집 중심가지의 거리를 재는 특성을 추가할 수 있다.
>    - 해안 근집성 특성이 유용할 수 있을까?
>    - 북부 캘리포니아에서는 Bay Area를 제외하고는 해안가의 주택 가격 특징은 높게 나타나지 않는데?



### 2) 상관관계 조사



*""**상관계수***

*선형적 상관관계를 측정한다. 비선형적 관계가 있는 경우 잡아내지 못한다.*

*상관계수는 기울기와 관련이 없다.""*



수치형 특성 간 상관관계를 조사함으로써 특성 조합, 특성공학 등에 대한 통찰을 얻을 수 있다.



* 전체 특성 간 상관계수 조사 : `.corr()`
* 타깃 속성과 다른 특성 간 상관관계 조사.
* 산점도 행렬



### 산점도 행렬

* 숫자형 특성 사이에 산점도를 그리는 `scatter_matrix` 함수 사용.

* 모든 그래프를 한 페이지에 그릴 수 없는 경우, 타깃 속성과 상관관계가 높아 보이는 특성을 선택하여 살펴본다.

* 옵션을 설정해 대각선 방향에는 히스토그램(`hist`)을 그리거나 커널 밀도 추정(`kde`)을 그릴 수 있다.

  > 실습 예제에서 생성한 산점도 행렬은 다음과 같다.
  >
  > ![scatter matrix]({{site.url}}/assets/images/scatter_matrix_plot.png)

* 산점도 행렬에서 유용할 것 같은 특성은 확대하여 살펴본다.

  > 실습 예제에서는 중간 소득과의 연관성이 높아 보인다.
  >
  > ![median income scatter]({{site.url}}/assets/images/income_vs_house_value_scatterplot.png)
  >
  > 이를 통해 다음과 같은 통찰을 얻을 수 있다.
  >
  > 1. 상관관계가 매우 강하다. 위쪽으로 향하는 경향을 볼 수 있고, 포인트들이 멀리 퍼져 있지 않다.
  > 2. 가격 제한 값이 50만 달러에서 수평으로 형성되어 있다.
  > 3. 45만 달러, 35만 달러, 28만 달러 부근에 직선적으로 데이터 포인트들이 밀집되어 있다. 알고리즘이 이상한 데이터 형태를 학습하지 않도록 해당 구역을 제거하는 것이 좋다.



### 3) 특성 조합으로 실험

여러 





### 4) 기타

* 정제할 데이터를 확인한다.
* 상관관계가 있는 특성을 조합한다.
* 데이터를 변형하여 분포를 바꾼다(*ex. 꼬리가 두꺼운 분포는 로그스케일 적용*)









---

# 실습

## 캘리포니아 주택 가격 예측 모델

>  실습 진행 파일 : [ae13655](https://github.com/sirzzang/Hands-on-Machine-Learning/blob/master/handon-ml-chap2-ML_endtoend_housing.ipynb)



* 히스토그램에서 중간 주택 연도, 중간 주택 가격에 이상치가 많은 줄 알았다. 알고 보니 상한값을 설정한 것이었다.











---

# 배운 점

* 모든 단계에서 **판단**이 중요하다. 그러나 이 판단은 절대 혼자 진행해서는 안 된다. 같은 팀원, 다른 팀과 협업하고, domain 지식을 적용해야 한다면 전문가의 조언을 구해야 한다.
  * 문제를 정의하고, 현재 솔루션은 무엇이 있는지, 어떻게 활용될 것인지와 같은 큰 그림을 그리는 것뿐만 아니라, 중요한 특성을 선택하고, 결측치나 이상치를 처리하는 과정에 있어서 올바른 판단을 내려야 한다. 그렇지 않다면 머신러닝 시스템의 성능이 떨어지게 된다.
  * 그러나 이 판단은 혼자 진행해서는 안 된다. 반드시 다른 팀과 협업하고, 모든 단계별로 가정이나 작업 상황을 나열하며 팀원들과  진행 방향을 설정해야 한다. 한편 domain , 전문가의 조언을 구해야 한다.



* 훈련 세트에서 **테스트 세트와 검증 세트의 차이**를 드디어 깨달았다.
  * 테스트 세트 : 실전에 배치되기 전, 모델의 일반화 오차 추정. 실전에 들어가기 전(공모전의 경우에는 test data set을 적용하기 전) *한 번만* 사용한다.
  * 검증 세트 : 모델의 비교를 위해 사용. 훈련 데이터의 훈련 세트를 나누어 가장 좋은 모델을 고르고 비교하는 데 사용한다.
* 실습을 통해 data load, prepare 단계에서 **함수를 이용**하는 것이 편하다는 것을 깨달았다. [DACON 천체 이미지 분류 공모전]()에 참여하면서 팀원에게 배운 것 중 하나이기도 하다. 머신러닝의 첫 단계는 데이터 적재이므로, 효율적인 data load를 위해 어떻게 data를 합칠지, 그것을 함수 안에 어떻게 구현할지 생각하는 습관을 들이자.





---

# 더 공부하고 싶은 것

* 1장 실습 진행 파일에 있어서 code inspection([063e4ad](https://github.com/sirzzang/Hands-on-Machine-Learning/commit/0d5725746929d47383ef51837933efeb6a0378e2))
  * prepare_country_stats : data load + combine 시 나중에 자주 사용할 수 있을 것이라 판단된다.
  * matplotlib 그림 초기 설정, 저장 관련.
* 캘리포니아 예제에서, "군집 알고리즘을 사용해 주요 군집을 찾고, 군집 중심가지의 거리를 재는 특성을 추가할 수 있다."고 했는데, 어떻게 할 수 있을까?