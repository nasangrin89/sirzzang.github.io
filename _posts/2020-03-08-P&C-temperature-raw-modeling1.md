---
title: "[DACON] AI프렌즈 시즌1 온도 추정 경진대회 - 기본 모델링_1"
excerpt: 온도 추정 경진대회의 데이터 탐색 내용입니다.
categories:
- P&C
toc : true
tags:
- 공모전
- 기본 모델링
- 기후
- 온도
- 센서
last_modified_at: 2020-03-08
---






# AI프렌즈 온도 추정 경진대회 기본 모델링_1

[작업 파일 1](https://github.com/sirzzang/data_competition/blob/master/[DACON]온도추정경진대회/[temperature]Y18_fillna_byStats.ipynb) : label 만들기

[작업 파일 2](https://github.com/sirzzang/data_competition/blob/master/[DACON]온도추정경진대회/[temperature]test_modeling_1(Y18_mean).ipynb) : 평균값으로 채운 훈련세트에 대해 모델링 진행 후 점수 확인

​	\- [작업파일 2-1](https://github.com/sirzzang/data_competition/blob/master/%5BDACON%5D%EC%98%A8%EB%8F%84%EC%B6%94%EC%A0%95%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/%5Btemperature%5Dtest_modeling_2(Y18_mean).ipynb) : 평균값 + id를 시간으로 바꾸고 모델링 진행 후 점수 확인.

​	\- 작업파일 2-2 : 평균값 + id를 시간으로 바꾸고 + 누적 강수량, 일사량 해체 후 점수 확인. 

[작업 파일 3 : 중간값으로 채운 훈련세트에 대해 모델링 진행 후 점수 확인]()



> 지난 회의(20200306) 이후, Y18의 값을 만들어 기본적인 모델링을 진행하고 그 결과를 확인하기로 했다. 그 중 내가 맡은 부분의 작업(평균값, 중간값 활용하여 채우고, 기본 모델링 진행)을 진행한다.





## *작업 내용 요약*



**label 만들기**

1. Y00~Y17 까지의 **평균**, **중간값**을 활용해 Y18의 결측치를 채웠다.
2. 평균값으로 채웠을 때, 중간값으로 채웠을 때 각각에 대해 Y00~Y17까지의 열을 drop한 후,  train data로 저장한다.



**label 만든 후 상관관계 확인**

계층적 샘플링을 진행할 때, 어떤 열을 활용할지 결정하기 위한 목적에서 진행했다.



**모델링**

조정할 파라미터의 수가 많지 않은 모델 여러 개를 시도하고, 이후 가장 가능성 있는 모델을 선정하여 특성 공학, 파라미터 튜닝 등을 진행하며 성과를 향상시키기 위한 목적이다.

1. 계층적 샘플링 진행

   * 평균값으로 채웠을 때, 중간값으로 채웠을 때 모두 X32가 가장 상관관계가 높게 나왔다.
   * X32 열의 값을 5개의 구간으로 나누고, `StratifiedShuffleSplit`을 활용해 계층적 샘플링을 진행한다.

2. 기본 모델 설계

   * [scikit-learn 지도학습](https://scikit-learn.org/stable/supervised_learning.html)에서, 기본적으로 활용할 수 있을 만한 regressor 알고리즘을 사용한다.
     * linear regression model
     * SVM(linear kernel)
     * decision tree model
     * bayesian regression model
     * nearest neighbors regression model
   * 다음의 지도학습 알고리즘 분류표에 따라, scaling을 진행해야 하는 알고리즘에서만 scaling을 진행한다.

   ![supervised learning algorithms]({{site.url}}/assets/images/model_scaling.png)

3. `random_state` 42로 설정
4. 10겹 교차검증 진행 : `neg_mean_sqared_error`
5. 파라미터 조정
   * 기본적으로 `GridSearchCV`를 사용한다.
   * 성능이 더 향상될 여지가 있다고 판단되면, `GridSearchCV`의 best parameter 이후의 범위에서 `RandomizedSearchCV` 사용한다.
6. 점수가 가장 좋게 나온 모델에 대해, [DACON 점수 측정 함수](https://newfront.dacon.io/competitions/official/235584/overview/)를 적용해 보고, 리더보드에 제출하여 그 차이를 판단한다.





## label 만들기

평균, 중간값을 활용해 Y18을 채우는 작업은 어렵지 않게 진행되었다.



### 상관관계 확인

오히려 새롭게 label을 만들고, Y18과 X00~X39 중 어떤 열이 상관관계가 높은지 판단하는 작업을 다시 진행했다. 

* [첫 데이터 탐색 단계](https://sirzzang.github.io/P&C-temperature-data-exploration1/)에서와는 달리, 센서 데이터만을 활용해 라벨을 만들었으므로, 상관관계가 어떻게 달라질지 궁금했다.
* 이후 계층적 샘플링을 진행할 때, 어떤 열을 기준으로 삼을 지 판단할 수 있다.



#### 평균값으로 채운 경우


**양의 상관관계**

| 0.9 이상 | 0.4 이상<br />0.7 미만 |
| :------: | :--------------------: |
|   X32    |          X26           |
|   X31    |          X24           |
|   X00    |          X18           |
|   X07    |          X34           |
|   X28    |          X11           |
|          |          X25           |
|          |          X17           |
|          |          X03           |

* 강한 양의 상관관계 : X00, X07, X28, X31, X32 = 전부 기온이고, 0.9 이상.
* 중간 수준의 양의 상관관계 : 특이하게, 0.9 이하인 것 중 가장 큰 값은 0.599이다.
  * X26, X24, X18, X03 : 풍속
  * X34, X11 : 일일 누적일사량
  * X25, X17 : 풍향
* 이전과는 달리 중간 수준의 양의 상관관계에서 큰 0.6 이상인 것이 없지만, 중간 수준의 상관관계로 분류되는 항목은 늘어났다.
* 일일 누적일사량의 경우, 일별 일사량으로 나누기로 했기 때문에 현재 단계에서는 큰 의미를 부여하지 않는다.
* 계층적 샘플링을 진행할 때는, X32를 기준으로 한다.


**음의 상관관계**

| -0.7 이하 | -0.7 초과<br />-0.4 이하 |
| :-------: | :----------------------: |
|    X12    |           X38            |
|    X30    |                          |
|    X37    |                          |
|    X20    |                          |

* 강한 음의 상관관계, 중간 수준의 음의 상관관계 모두 습도이다.
* X38보다 작은 음의 상관관계는 전부 -0.17 이하로, 이전과 다른 양상을 보인다.



#### 중간값으로 채운 경우

**양의 상관관계**

| 0.9 이상 | 0.4 이상<br />0.7 미만 |
| :------: | :--------------------: |
|   X32    |          X26           |
|   X00    |          X24           |
|   X31    |          X18           |
|   X07    |          X25           |
|   X28    |          X34           |
|          |          X11           |
|          |          X17           |
|          |          X03           |

* 순서만 다를 뿐, 평균값으로 채웠을 때와 같은 양상을 보인다.
* 계층적 샘플링을 진행할 때는, X32를 기준으로 한다.



**음의 상관관계**

| -0.7 이하 | -0.7 초과<br />-0.4 이하 |
| :-------: | :----------------------: |
|    X12    |           X38            |
|    X20    |                          |
|    X30    |                          |
|    X37    |                          |

* 이 역시 순서만 다를 뿐, 평균값으로 채웠을 때와 같은 양상을 보인다.







## 모델링 진행_평균값으로 채웠을 때



### 계층적 샘플링 진행

* 타깃 속성인 Y18과 가장 상관관계가 높게 나타난 X32 속성을 기준으로, 값을 5개의 범주로 나누었다.

![X32 category]({{site.url}}/assets/images/mean_X32_category_hist.png)

* 전체 훈련 데이터에서 X32_cat 열의 비중과, test_size를 0.2로 하여 계층적 샘플링을 진행하고 난 뒤 X32_cat 열의 비중을 살펴보면 다음과 같다.

|      | 전체 train set | strat_train_set | strat_test_set |
| ---- | -------------- | --------------- | -------------- |
| 5.0  | 0.300926       | 0.300973        | 0.300736       |
| 4.0  | 0.229798       | 0.229939        | 0.229232       |
| 6.0  | 0.216330       | 0.216259        | 0.216614       |
| 7.0  | 0.186027       | 0.186004        | 0.186120       |
| 8.0  | 0.066919       | 0.066825        | 0.067298       |



### 트리 기반 모델

>  scaling을 진행하지 않고 모델링한다.



1. Decision Tree Model
   * 파라미터 탐색은 진행하지 않았다. Random Forest 모델에서 파라미터 탐색을 하는 것이 나을 것이라 판단했다.
   * 10겹 교차검증을 진행한 결과, neg MSE 점수가 -1.3789 정도였다.



2. Random Forest Model

   2-1. 처음에 id를 넣고 학습을 진행했다. 

   * 파라미터 탐색을 진행했다.
   
     * `n_estimators` : 200, 500, 1000.
  * `max_features` : 20, 30, 40.
     
* `bootstrap` : True, False. 다만, False일 경우 n_estimators가 200인 경우는 제외했다.
     
   * 가장 좋은 파라미터 조합으로 `bootstrap`은 `False`, `n_estimators`가 500, `max_features`가 20인 것으로 나왔다. 이 때의 모델을 저장한다.
   
     * `bootstrap` 옵션은 확실히 False일 때가 좋아 보인다. 유의미하게 score가 상승한다. 그러나, `max_features`가 40, 즉, 모든 feature를 다 사용할 때는 score가 확 커진다. 
  * `max_features` 옵션 역시, 20개 전후가 가장 좋아 보인다. 모든 경우에 대해서 30, 40개일 때보다 20개일 때가 더 점수가 좋다.
     
* `n_estimators` 옵션은 일단 많다고 좋은 것 같지는 않다. 200에서 500으로 갈 때는 점수가 상승하나, 500에서 1000으로 갈 때 유의미하게 점수가 좋아지지는 않는다.
     
   * 가장 좋은 파라미터 조합에서 bootstrap은 고정시켜 놓고, n_estimators와 max_features를 바꿔 가며 최적의 파라미터 조합을 테스트했다.

     * `n_estimators` = 500으로 고정하고, `max_features`를 10에서 30까지 바꿨다. 
     
        * 확실히, feature 수가 많을수록 검증 set에서 성능이 하락한다.
       * 그 결과, `max_features` = 12일 때 가장 좋았으며, train_score와 test_score의 변화는 다음과 같다. train_score의 점수와 test_score의 점수가 굉장히 다른 것을 보니, **과적합**이 있는 것 같다.

       ![overfitting?]({{site.url}}/assets/images/adjusting_max_features_0.png)

       * 특성 중요도를 파악한 결과, 대부분이 기온, 습도였다. *강한 상관관계*가 있다고 드러난 속성들이었기 때문에, **Random Forest 모델에서도 중요한 특성으로 이들을 선택하는 것이 흥미로웠다.**


   2-2. 문득, 특성 중요도를 파악하다, id를 넣고 학습시킨 것을 발견했다. 급한 마음에 처음부터 학습을 다시 시켰으나, 갑자기 다음과 같은 궁금증이 떠올랐다.

   >  **"*id를 시간을 나타내는 특성으로서 활용하면 되지 않을까? 왜 id가 학습에 중요한 것으로 나타났을까?*"**

   2-3. 일단 id를 제외하고 위의 과정을 반복했다. 그런데 2-1의 best parameter 조합에서는 -0.30으로 나타나던 mean_test_score가 갑자기 -0.35가 되었다. DACON 리더보드에 올린 결과, **5.4197504594점**이 나왔다.



* baseline 코드가 6.6435191177점이었다는 것을 감안하면, 더 높게 나온 리더보드 점수로 감안할 때, Random Forest 모형을 사용해 회귀를 진행한 것이 크게 틀린 방향은 아니었다.
* 여전히 id를 뺀 후에 점수가 낮아진 것에 미련이 남는다. 혹시 id를 포함한다면, 혹은 id를 다른 방식으로 변환하여 학습에 사용한다면 점수가 높아질 수 있지 않을까?



3. Linear Regression Model
   * 기본 파라미터로, 모든 특성을 활용해 학습을 진행했다.
   * 10겹 교차검증을 통해 얻은 neg_MSE 점수가 Random Forest 모델보다 낮게 나와 더 작업을 진행하지 않았다.



4. SVR Model
   * kernel = linear로 설정했다.
   * `C`, `gamma` 값을 조정해 grid search를 진행했는데, 시간이 무척(x100) 오래 걸린다.
   * 10겹 교차검증을 진행한 결과 neg_MSE 점수가 -2.23점 정도였다. Linear Regression Model과 크게 다르지 않았다. 그런데 test set에 넣었을 때 점수가 무려(...!) *7492095.366064896점*이 나왔다. 도대체 무슨 일인지 어디서 잘못된 것 같다.





# 느낀 점

소기의 성과가 있었으나 여전히 과적합이 있고, feature engineering이 진행되지 않았다. 차원 축소, 특성 조합 등의 방법을 생각해보아야 한다.





# 더 진행해야 할 작업

* 중간값으로 채운 파일에 대해 동일한 작업 진행하기.
* 서포트 벡터 머신 회귀 모형 조정하기. + PCA 적용할 수 있는지 공부해 보기.
* 코드 함수화, 파이프라인화하기.
* 조금 더 깊은 단계의 회귀 모형 찾아보기.
* 시각화 단계 다시 돌아가서 진행하기.
* 베이스라인 코드 뜯어 보기.






# 논의하고 싶은 내용

* 10분 간격으로 측정된 데이터이고, id가 측정된 분 단위를 나타내므로 시각을 나타낼 수 있지 않을까? 예컨대, id가 144개씩 묶이면 하루가 되기 때문에, id를 144로 나눠서 나머지가 작으면 아침이고, 크면 밤이라고 생각할 수 있을 것이다. 그렇다면 이것은 기온, 나아가 측정 온도에 영향을 미칠 수 있지 않을까?
* 베이스라인 코드가 Y15, Y16 속성을 활용해 Y18을 예측했다. 이를 발전시킬 수는 없을까?





